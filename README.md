# Panoptiscope
An Interactive System for Exploring Surveillance Through Sound. Built with Max/MSP, it explores how digital and acoustic monitoring technologies operate and how individuals may unknowingly be subject to observation. The project blends technical implementation with critical reflection on privacy, surveillance, and information control.

## Overview
This project investigates the aesthetics and structure of surveillance by transforming metadata (such as coordinates or system logs) into real-time sound output and visual feedback. It serves both as a conceptual exploration and a functional prototype of how data can be interpreted and represented in alternative modalities.

## Tech stack
- **Max/MSP (Cycling '74):** Visual programming for audio synthesis and control logic
- **Jitter:** Video and graphical interface overlays (e.g. simulating terminal feedback or eye-tracking data)
- **Custom Audio Samples:** Environmental field recordings used for ambient and reactive sound layers
- **Basic Data Mapping:** Location/trigger-based audio modulation

## Features

- Real-time sound processing based on internal or external input
- Visual feedback in the style of terminal interfaces or surveillance UIs
- Modular Max patches for easy expansion or performance use
- Prototype-ready for future integration with sensors or live input (e.g. microphones, webcams, eye trackers)

